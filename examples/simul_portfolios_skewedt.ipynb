{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dcor as dc\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import norm\n",
    "from math import sqrt,  tanh, ceil, log, cos, pi, sin\n",
    "import seaborn as sns\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "from IPython.display import display, Math, Latex\n",
    "from scipy.io import loadmat\n",
    "from scipy.linalg import pinv2, sqrtm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from necessary files \n",
    "import os\n",
    "original_dir = os.getcwd()\n",
    "os.chdir('..\\\\src\\\\robustOptimPack\\\\Utils')\n",
    "from helper_funcs import *\n",
    "os.chdir('..\\\\src\\\\robustOptimPack\\\\MVPortfolio')\n",
    "from MVPortfolio_funcs import *\n",
    "os.chdir('..\\\\src\\\\robustOptimPack\\\\HCPortfolio')\n",
    "from HCPortfolio_funcs import *\n",
    "os.chdir('..\\\\src\\\\robustOptimPack\\\\PortfolioBacktest')\n",
    "from Backtest_funcs import *\n",
    "os.chdir('..\\\\src\\\\robustOptimPack\\\\wrapping')\n",
    "from wrapping_funcs import *\n",
    "os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 100\n",
    "n_obs_vec = [1000]\n",
    "dates_vec = pd.date_range('2018-01-01', periods=1000, freq='D')\n",
    "res_mat_noout= np.ones((len(n_obs_vec),n_reps, 4 ))\n",
    "delta_t = 1/360\n",
    "mean_vec = np.array([-0.45, -0.25, -0.2, -0.15, -0.1, -0.05, 0.05, 0.08, 0.1, 0.15, 0.2, 0.21, 0.25, 0.3, 0.45])*delta_t\n",
    "sd_vec = np.array([0.5, 0.2, 0.3, 0.25, 0.3, 0.2, 0.25, 0.23, 0.2, 0.4, 0.2, 0.25, 0.3, 0.15, 0.5]) *np.sqrt(delta_t)\n",
    "sd_white_noise = sqrt(0.01)\n",
    "nu_vec = np.linspace(start=5, stop=75, num=15)\n",
    "_lambda_vec = np.round(np.linspace(start=-1, stop=1, num=15),2)\n",
    "n_clusts = 8\n",
    "n_assets = 20\n",
    "link_method = 'average'\n",
    "out_fraction = 0.2\n",
    "assets_in_groups = np.repeat([5,4,3,2,1], [1,1,2,1,3])\n",
    "out_dist = 64\n",
    "test_window = 30\n",
    "train_window = 180"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic simulation without outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for cur_nobs in range(len(n_obs_vec)): \n",
    "     n_obs = n_obs_vec[cur_nobs]\n",
    "     #print(\"current n_obs is \", n_obs)\n",
    "     \n",
    "     for cur_rep in range(n_reps):\n",
    "        \n",
    "         np.random.seed(cur_rep)\n",
    "         #print('current rep', cur_rep+1)\n",
    "         data_assets = np.zeros((n_obs, 1))\n",
    "         \n",
    "         for group_ind in assets_in_groups: \n",
    "             #print('group_ind is ', group_ind)\n",
    "             #initialise data matrix for that group: \n",
    "             data_group_ind = np.zeros((n_obs, group_ind))\n",
    "             #generate skewed t variate for that group  \n",
    "             # sample the kurtosis parameter \n",
    "             nu_l = np.random.choice(nu_vec, size = 1)\n",
    "             _lambda_l  =  np.random.choice(_lambda_vec, size = 1)\n",
    "             #print('nu: ', nu_l, ':lambda ', _lambda_l)\n",
    "             y_l_t = generate_skt(n_obs, nu_l, _lambda_l).flatten() \n",
    "             \n",
    "             for asset_ind in range(group_ind): \n",
    "                 \n",
    "                 #sample mean and volatility for current asset in current group \n",
    "                 asset_i_mean = np.random.choice(mean_vec, size = 1)\n",
    "                 asset_i_vol = np.random.choice(sd_vec, size = 1)\n",
    "                 \n",
    "                 data_group_ind[:,asset_ind] = asset_i_mean + np.multiply(y_l_t, asset_i_vol)\n",
    "                 #print('data_group shape ', data_group_ind.shape)\n",
    "             data_assets = np.column_stack((data_assets, data_group_ind))\n",
    "             #print('data_asset shape ', data_assets.shape)\n",
    "         \n",
    "         dat_sim = pd.DataFrame(data_assets[:,1:])\n",
    "         dat_sim.set_index(dates_vec, inplace=True)\n",
    "         volumes_df = pd.DataFrame(np.ones((dat_sim.shape[0], dat_sim.shape[1])))# we want to use all assets\n",
    "         #initialise portfolio objects \n",
    "         portfolio_equal_crypto = EqualWeightPortfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='EW', init_amount_invested=1)\n",
    "\n",
    "\n",
    "         portfolio_cov_crypto = MVPortfolio(asset_names=list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='MV',init_amount_invested=1,long_only=True)\n",
    "\n",
    "         portfolio_HRP_crypto_cor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_cor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'sample', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_dcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_dcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'dcor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_wcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_wcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_cor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_wdcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data= dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_wdcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_dcor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HERC_crypto_cor_average_sil = HERC_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data= dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_cor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'sample', linkage_method = \"average\",num_clusters_method = 'silhouette' )\n",
    "\n",
    "         portfolio_HERC_crypto_dcor_average_sil = HERC_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_dcor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'dcor', linkage_method = \"average\", num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_HERC_crypto_wcor_average_sil = HERC_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_wcor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_cor', linkage_method = \"average\",num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_HERC_crypto_wdcor_average_sil = HERC_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_wdcor_sil', init_amount_invested=1, \n",
    "                                                                cov_method = 'sample', cor_method = 'robust_dcor', linkage_method = \"average\",num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_cluster_sharpe_sil = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe', init_amount_invested=1, \n",
    "                                                    cor_method = 'sample', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR', init_amount_invested=1, \n",
    "                                                    cor_method = 'sample', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "        \n",
    "         portfolio_cluster_sharpe_sil_dcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_dcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'dcor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_dcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_dcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'dcor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "         portfolio_cluster_sharpe_sil_wcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_wcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_cor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_wcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_wcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_cor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "         portfolio_cluster_sharpe_sil_wdcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_wdcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_dcor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_wdcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_wdcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_dcor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "         list_of_portfolios = [portfolio_equal_crypto, portfolio_cov_crypto, \n",
    "                            portfolio_HRP_crypto_cor_average,portfolio_HRP_crypto_dcor_average,portfolio_HRP_crypto_wcor_average,portfolio_HRP_crypto_wdcor_average,\n",
    "                            portfolio_HERC_crypto_cor_average_sil,portfolio_HERC_crypto_dcor_average_sil,portfolio_HERC_crypto_wcor_average_sil,portfolio_HERC_crypto_wdcor_average_sil,\n",
    "                            portfolio_cluster_sharpe_sil,\n",
    "                            portfolio_cluster_CVaR_sil, \n",
    "                            portfolio_cluster_sharpe_sil_dcor,\n",
    "                            portfolio_cluster_CVaR_sil_dcor, \n",
    "                            portfolio_cluster_sharpe_sil_wcor,\n",
    "                            portfolio_cluster_CVaR_sil_wcor, \n",
    "                            portfolio_cluster_sharpe_sil_wdcor, \n",
    "                            portfolio_cluster_CVaR_sil_wdcor\n",
    "                            ]\n",
    "\n",
    "         portfolios_backtest_crypto = backtest_crypto_portfolios(list_of_portfolios,returns_data=dat_sim,\n",
    "                                                                log_returns_data = dat_sim,\n",
    "                                                                is_price_data=False, volumes = volumes_df, dates = dates_vec, K=n_assets, \n",
    "                                                                train_window_size = train_window, transaction_cost = 0,\n",
    "                                                                test_window_size = test_window,rebalance_window_size=test_window)\n",
    "         portfolios_backtest_crypto.run_backtest()\n",
    "         \n",
    "         if (cur_rep == 0): \n",
    "             results_df = portfolios_backtest_crypto.out_of_sample_results()\n",
    "         else: \n",
    "             results_df = pd.concat([results_df,portfolios_backtest_crypto.out_of_sample_results()])\n",
    "             \n",
    " \n",
    "\n",
    "         \n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['index1'] = results_df.index\n",
    "stat_desc = round(results_df.groupby('index1').median(),2)\n",
    "print(stat_desc.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(dat_sim))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation with cellwise outliers in all variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = n_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_nobs in range(len(n_obs_vec)): \n",
    "     n_obs = n_obs_vec[cur_nobs]\n",
    "     #print(\"current n_obs is \", n_obs)\n",
    "     \n",
    "     for cur_rep in range(n_reps):\n",
    "        \n",
    "         np.random.seed(cur_rep)\n",
    "         #print('current rep', cur_rep+1)\n",
    "         data_assets = np.zeros((n_obs, 1))\n",
    "         \n",
    "         # generate index of outlying columns \n",
    "         out_cols = np.sort( np.random.randint(n_assets, size = out_dim))\n",
    "         out_col_counter = 0\n",
    "         \n",
    "         \n",
    "         for group_ind in assets_in_groups: \n",
    "             #print('group_ind is ', group_ind)\n",
    "             #initialise data matrix for that group: \n",
    "             data_group_ind = np.zeros((n_obs, group_ind))\n",
    "             nu_l = np.random.choice(nu_vec, size = 1)\n",
    "             _lambda_l  =  np.random.choice(_lambda_vec, size = 1)\n",
    "             #print('nu: ', nu_l, ':lambda ', _lambda_l)\n",
    "             y_l_t = generate_skt(n_obs, nu_l, _lambda_l).flatten()\n",
    "             \n",
    "             for asset_ind in range(group_ind): \n",
    "                 \n",
    "                 #sample mean and volatility for current asset in current group \n",
    "                 asset_i_mean = np.random.choice(mean_vec, size = 1)\n",
    "                 asset_i_vol = np.random.choice(sd_vec, size = 1)\n",
    "                 \n",
    "                 data_group_ind[:,asset_ind] = asset_i_mean + np.multiply(y_l_t, asset_i_vol)\n",
    "                 #print('data_group shape ', data_group_ind.shape)\n",
    "                 \n",
    "                 # generate outliers if the current column should contain outliers \n",
    "                 if out_col_counter in out_cols: \n",
    "                     #print('out col ', out_col_counter, ' max ', np.max(data_group_ind[:,asset_ind]))\n",
    "                     outliers_ind = np.random.randint(n_obs, size= round(out_fraction *n_obs) )\n",
    "                     data_group_ind[outliers_ind,asset_ind] =  random.sample([-1,1], 1)[0] *(np.max(data_group_ind[:,asset_ind]) *out_dist)/sqrt(out_dim)\n",
    "                     #print('out col ', out_col_counter, ' max ', np.max(data_group_ind[:,asset_ind]))\n",
    "                 out_col_counter +=1 \n",
    "             data_assets = np.column_stack((data_assets, data_group_ind))\n",
    "             #print('data_asset shape ', data_assets.shape)\n",
    "         \n",
    "         dat_sim = pd.DataFrame(data_assets[:,1:])\n",
    "         dat_sim.set_index(dates_vec, inplace=True)\n",
    "         volumes_df = pd.DataFrame(np.ones((dat_sim.shape[0], dat_sim.shape[1])))# we want to use all assets\n",
    "         #initialise portfolio objects \n",
    "         portfolio_equal_crypto = EqualWeightPortfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='EW', init_amount_invested=1)\n",
    "\n",
    "         portfolio_cov_crypto = MVPortfolio(asset_names=list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='MV',init_amount_invested=1,long_only=True)\n",
    "\n",
    "         portfolio_HRP_crypto_cor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_cor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'sample', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_dcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_dcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'dcor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_wcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_wcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_cor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HRP_crypto_wdcor_average = HRP_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data= dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HRP_wdcor', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_dcor', linkage_method = \"average\")\n",
    "\n",
    "         portfolio_HERC_crypto_cor_average_sil = HERC_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data= dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_cor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'sample', linkage_method = \"average\",num_clusters_method = 'silhouette' )\n",
    "\n",
    "         portfolio_HERC_crypto_dcor_average_sil = HERC_portfolio(asset_names= list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_dcor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'dcor', linkage_method = \"average\", num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_HERC_crypto_wcor_average_sil = HERC_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets], data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_wcor_sil', init_amount_invested=1, \n",
    "                                                    cov_method = 'sample', cor_method = 'robust_cor', linkage_method = \"average\",num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_HERC_crypto_wdcor_average_sil = HERC_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='HERC_wdcor_sil', init_amount_invested=1, \n",
    "                                                                cov_method = 'sample', cor_method = 'robust_dcor', linkage_method = \"average\",num_clusters_method = 'silhouette')\n",
    "\n",
    "         portfolio_cluster_sharpe_sil = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe', init_amount_invested=1, \n",
    "                                                    cor_method = 'sample', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR', init_amount_invested=1, \n",
    "                                                    cor_method = 'sample', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "        \n",
    "         portfolio_cluster_sharpe_sil_dcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_dcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'dcor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_dcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_dcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'dcor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "         portfolio_cluster_sharpe_sil_wcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_wcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_cor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_wcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets] , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_wcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_cor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "         portfolio_cluster_sharpe_sil_wdcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_sharpe_wdcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_dcor', linkage_method = \"complete\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"sharpe\" )\n",
    "\n",
    "         portfolio_cluster_CVaR_sil_wdcor = max_cluster_portfolio(asset_names=list(volumes_df.columns.values)[0:n_assets]  , data=dat_sim, is_price_data=False, risk_free_rate=0, period_length=1, name='cluster_CVaR_wdcor', init_amount_invested=1, \n",
    "                                                    cor_method = 'robust_dcor', linkage_method = \"average\", num_clusters_type = 'search', num_clusters_method = 'silhouette', risk_method = \"CVaR\" )\n",
    "\n",
    "\n",
    "         list_of_portfolios = [portfolio_equal_crypto, portfolio_cov_crypto, \n",
    "                            portfolio_HRP_crypto_cor_average,portfolio_HRP_crypto_dcor_average,portfolio_HRP_crypto_wcor_average,portfolio_HRP_crypto_wdcor_average,\n",
    "                            portfolio_HERC_crypto_cor_average_sil,portfolio_HERC_crypto_dcor_average_sil,portfolio_HERC_crypto_wcor_average_sil,portfolio_HERC_crypto_wdcor_average_sil,\n",
    "                            portfolio_cluster_sharpe_sil,\n",
    "                            portfolio_cluster_CVaR_sil, \n",
    "                            portfolio_cluster_sharpe_sil_dcor,\n",
    "                            portfolio_cluster_CVaR_sil_dcor,  \n",
    "                            portfolio_cluster_sharpe_sil_wcor,\n",
    "                            portfolio_cluster_CVaR_sil_wcor, \n",
    "                            portfolio_cluster_sharpe_sil_wdcor, \n",
    "                            portfolio_cluster_CVaR_sil_wdcor\n",
    "                            ]\n",
    "\n",
    "\n",
    "         portfolios_backtest_crypto = backtest_crypto_portfolios(list_of_portfolios,returns_data=dat_sim,\n",
    "                                                                log_returns_data = dat_sim,\n",
    "                                                                is_price_data=False, volumes = volumes_df, dates = dates_vec, K=n_assets, \n",
    "                                                                train_window_size = train_window, transaction_cost = 0,\n",
    "                                                                test_window_size = test_window,rebalance_window_size=test_window)\n",
    "         portfolios_backtest_crypto.run_backtest()\n",
    "         \n",
    "         if (cur_rep == 0): \n",
    "             results_df_cell = portfolios_backtest_crypto.out_of_sample_results()\n",
    "         else: \n",
    "             results_df_cell = pd.concat([results_df_cell,portfolios_backtest_crypto.out_of_sample_results()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cell['index1'] = results_df_cell.index\n",
    "stat_desc_cell = round(results_df_cell.groupby('index1').median(),2)\n",
    "print(stat_desc_cell.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5311ec2bf6f7d85cab2d580bd724fa76bee655ef41b8e1c97075e57971827f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
